{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/edwko/OuteTTS <br>\n",
        "https://huggingface.co/OuteAI/Llama-OuteTTS-1.0-1B <br>\n",
        "https://huggingface.co/OuteAI/Llama-OuteTTS-1.0-1B-GGUF <br>\n",
        "\n",
        "### Ethical Use Guidelines:<br>\n",
        "This text-to-speech model is intended for legitimate applications that enhance accessibility, creativity, and communication; prohibited uses include impersonation without consent, creation of deliberately misleading content, generation of harmful or harassing material, distribution of synthetic audio without proper disclosure, voice cloning without permission, and any uses that violate applicable laws, regulations, or copyrights."
      ],
      "metadata": {
        "id": "4fVVlc2qh6Xz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPfZpRYuMSNn"
      },
      "outputs": [],
      "source": [
        "#It will take 12 minutes\n",
        "!CMAKE_ARGS=\"-DGGML_CUDA=on\" pip install outetts --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjMJEOw_VBfR"
      },
      "outputs": [],
      "source": [
        "import outetts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LDio8nFfVHay"
      },
      "outputs": [],
      "source": [
        "interface = outetts.Interface(\n",
        "    config=outetts.ModelConfig.auto_config(\n",
        "        model=outetts.Models.VERSION_1_0_SIZE_1B,\n",
        "        # For llama.cpp backend\n",
        "        backend=outetts.Backend.LLAMACPP,\n",
        "        quantization=outetts.LlamaCppQuantization.FP16\n",
        "        # For transformers backend\n",
        "        # backend=outetts.Backend.HF,\n",
        "    )\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fr1llDOnVh49",
        "outputId": "f8b90334-a8ab-4f61-8138-cd5e714a9bcb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2025-04-08 07:39:49.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36moutetts.whisper.transcribe\u001b[0m:\u001b[36mtranscribe_once_word_level\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mLoading model turbo\u001b[0m\n",
            "100%|█████████████████████████████████████| 1.51G/1.51G [00:20<00:00, 77.7MiB/s]\n",
            "\u001b[32m2025-04-08 07:40:26.021\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36moutetts.whisper.transcribe\u001b[0m:\u001b[36mtranscribe_once_word_level\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1mTranscribing /content/Recording.wav\u001b[0m\n",
            "\u001b[32m2025-04-08 07:40:35.271\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36moutetts.whisper.transcribe\u001b[0m:\u001b[36mtranscribe_once_word_level\u001b[0m:\u001b[36m17\u001b[0m - \u001b[32m\u001b[1mTranscription: I love learning new things every day. The sun rises in the east.\u001b[0m\n",
            "/usr/local/lib/python3.11/dist-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
            "  warnings.warn(\"Possible clipped samples in output.\")\n",
            "100%|██████████| 2/2 [00:01<00:00,  1.43it/s]\n",
            "\u001b[32m2025-04-08 07:40:38.202\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36moutetts.version.interface\u001b[0m:\u001b[36msave_speaker\u001b[0m:\u001b[36m111\u001b[0m - \u001b[1mSpeaker saved to: /content/speaker.json\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "\n",
        "reference_audio = '/content/Recording.wav'  # @param {type: \"string\"}\n",
        "\n",
        "speaker = interface.create_speaker(reference_audio)\n",
        "# interface.save_speaker(speaker, \"/content/speaker.json\")\n",
        "# speaker = interface.load_speaker(\"speaker.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7iKRHcRWHAC",
        "outputId": "9336a6e2-3111-4477-b1fd-72c098d8e7ea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2025-04-08 07:53:34.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36moutetts.version.interface\u001b[0m:\u001b[36mchunk_generation\u001b[0m:\u001b[36m251\u001b[0m - \u001b[1mCreated: 1 text chunks\u001b[0m\n",
            "\u001b[32m2025-04-08 07:53:34.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36moutetts.version.interface\u001b[0m:\u001b[36mchunk_generation\u001b[0m:\u001b[36m253\u001b[0m - \u001b[1mProccessing: Chunk 1 / 1\u001b[0m\n",
            "0it [00:00, ?it/s]Llama.generate: 36 prefix-match hit, remaining 1059 prompt tokens to eval\n",
            "439it [00:07, 57.96it/s, tokens=1534, max tokens=8192]\n",
            "\u001b[32m2025-04-08 07:53:41.746\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36moutetts.version.playback\u001b[0m:\u001b[36msave\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mSaved audio to: /content/output.wav\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "text = 'Hello, how are you doing?'  # @param {type: \"string\"}\n",
        "audio_save_path = '/content/output.wav'  # @param {type: \"string\"}\n",
        "\n",
        "output = interface.generate(\n",
        "    config=outetts.GenerationConfig(\n",
        "        text=text,\n",
        "        generation_type=outetts.GenerationType.CHUNKED,\n",
        "        speaker=speaker,\n",
        "        sampler_config=outetts.SamplerConfig(\n",
        "            temperature=0.4\n",
        "        ),\n",
        "    )\n",
        ")\n",
        "\n",
        "# Save to file\n",
        "output.save(audio_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio, display\n",
        "print(\"Original Voice:\")\n",
        "display(Audio(reference_audio, autoplay=False))\n",
        "print(\"Cloned Voice:\")\n",
        "display(Audio(audio_save_path, autoplay=False))"
      ],
      "metadata": {
        "id": "oG8Ku3Jaf0R1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}