{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## ‚ö†Ô∏è Misuse & Abuse Policy  \n",
        "\n",
        "This speech generation model is for research and educational use only. The following are strictly prohibited:  \n",
        "\n",
        "- **Impersonation**: No mimicking real individuals without consent.  \n",
        "- **Misinformation**: No deceptive or misleading content (e.g., fake news, fraud, Scam).  \n",
        "- **Illegal Activities**: No use for harm, crime, or malicious purposes.  \n",
        "\n",
        "Use responsibly and ethically. üö´  \n",
        "## ‚ö†Ô∏è Disclaimer  \n",
        "\n",
        "The developers are **not responsible** for any misuse of this technology.  \n",
        "Unethical use is **strongly condemned**‚Äîfollow your **local laws** and use responsibly. üö´  \n"
      ],
      "metadata": {
        "id": "XXFeYXz6TmOO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Before Running [CSM](https://github.com/SesameAILabs/csm)\n",
        "\n",
        "### 1. Accept License Agreements  \n",
        "- [CSM-1B License](https://huggingface.co/sesame/csm-1b)  \n",
        "- [Llama-3.2-1B License](https://huggingface.co/meta-llama/Llama-3.2-1B)  \n",
        "\n",
        "### 2. Get Hugging Face Access Token  \n",
        "- Generate or retrieve your token from [Hugging Face Access Tokens](https://huggingface.co/settings/tokens)  \n",
        "\n",
        "### 3. Run CSM  \n",
        "Once the licenses are accepted and the access token is ready, you can proceed with setting up and running CSM.  \n"
      ],
      "metadata": {
        "id": "spQl2txYT-GG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "iNU9ZeM5R9Ls"
      },
      "outputs": [],
      "source": [
        "#@title Install CSM\n",
        "HF_TOKEN=\"asfdagfhjgsdfjhagdhjshjf\" # @param {type: \"string\"}\n",
        "root_path=\"/content\" # @param {type: \"string\"}\n",
        "\n",
        "#\n",
        "%cd $root_path\n",
        "!git clone https://github.com/SesameAILabs/csm.git\n",
        "%cd $root_path/csm\n",
        "!pip install -r requirements.txt\n",
        "!pip install -U openai-whisper\n",
        "!pip install gradio>=5.9.1\n",
        "!pip install click\n",
        "!pip install pydub>=0.25.1\n",
        "\n",
        "!apt-get update && apt-get install -y ffmpeg\n",
        "\n",
        "from huggingface_hub import login\n",
        "login(token=HF_TOKEN)\n",
        "\n",
        "#Restart Sesstion otherwise huggingface authentication will not work\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "import time\n",
        "time.sleep(5)\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create /content/csm/app.py\n",
        "\n",
        "%%writefile /content/csm/app.py\n",
        "from generator import load_csm_1b,Segment\n",
        "import torchaudio\n",
        "import torch\n",
        "import os\n",
        "import whisper\n",
        "import hashlib\n",
        "import os\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# Ensure the upload directory exists\n",
        "os.makedirs(\"./upload/\", exist_ok=True)\n",
        "os.makedirs(\"./result\",exist_ok=True)\n",
        "if torch.backends.mps.is_available():\n",
        "    device = \"mps\"\n",
        "elif torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "\n",
        "generator = load_csm_1b(device=device)\n",
        "\n",
        "whisper_model = whisper.load_model(\"tiny\")\n",
        "\n",
        "\n",
        "old_hash_key = \"\"  # Stores the last processed audio hash\n",
        "old_transcripts = []  # Stores cached transcripts\n",
        "\n",
        "\n",
        "\n",
        "def csm_tts(text,speaker_id=0):\n",
        "  audio = generator.generate(\n",
        "      text=text,\n",
        "      speaker=speaker_id,\n",
        "      context=[],\n",
        "      max_audio_length_ms=10_000,\n",
        "  )\n",
        "  save_path=f\"./result{text[:20]}.wav\"\n",
        "  torchaudio.save(save_path, audio.unsqueeze(0).cpu(), generator.sample_rate)\n",
        "  return save_path\n",
        "\n",
        "\n",
        "def get_audio_hash(audio_paths):\n",
        "    \"\"\"Generate a hash for the given audio files to check for identical content.\"\"\"\n",
        "    hasher = hashlib.md5()\n",
        "    for path in audio_paths:\n",
        "        with open(path, \"rb\") as f:\n",
        "            hasher.update(f.read())  # Read the file in binary mode and update hash\n",
        "    return hasher.hexdigest()  # Return unique hash for audio files\n",
        "\n",
        "\n",
        "\n",
        "#Because on stereo csm giving error\n",
        "def convert_stereo_to_mono(audio_paths):\n",
        "  mono_audio_paths=[]\n",
        "  for input_file in audio_paths:\n",
        "    base_name = os.path.basename(input_file)  # Extract filename\n",
        "    output_file = f\"./upload/{os.path.splitext(base_name)[0]}_mono.wav\"  # Append \"_mono\"\n",
        "\n",
        "    audio = AudioSegment.from_file(input_file)\n",
        "    mono_audio = audio.set_channels(1)  # Convert to mono\n",
        "    mono_audio.export(output_file, format=\"wav\")  # Save as WAV\n",
        "    mono_audio_paths.append(output_file)\n",
        "  return mono_audio_paths\n",
        "\n",
        "def get_transcripts(audio_paths):\n",
        "    global old_hash_key, old_transcripts  # Use global cache\n",
        "\n",
        "    hash_key = get_audio_hash(audio_paths)  # Generate a hash for current files\n",
        "\n",
        "    # If hash matches previous one, return cached transcripts\n",
        "    if hash_key == old_hash_key and old_transcripts:\n",
        "        # print(\"Using cached transcripts\")  # Debug message\n",
        "        return old_transcripts\n",
        "\n",
        "    # print(\"Generating new transcripts\")  # Debug message\n",
        "    transcripts = []\n",
        "    for audio_path in audio_paths:\n",
        "        result = whisper_model.transcribe(audio_path)[\"text\"].strip()\n",
        "        transcripts.append(result)  # Append correct result\n",
        "\n",
        "    # Update cache\n",
        "    old_transcripts = transcripts\n",
        "    old_hash_key = hash_key\n",
        "\n",
        "    return transcripts\n",
        "\n",
        "\n",
        "def load_audio(audio_path):\n",
        "    audio_tensor, sample_rate = torchaudio.load(audio_path)\n",
        "    audio_tensor = torchaudio.functional.resample(\n",
        "        audio_tensor.squeeze(0), orig_freq=sample_rate, new_freq=generator.sample_rate\n",
        "    )\n",
        "    return audio_tensor\n",
        "\n",
        "def get_segments(audio_paths,speaker_id=0):\n",
        "  segments = []\n",
        "  transcripts_list=get_transcripts(audio_paths)\n",
        "  for audio_path,transcript in zip(audio_paths,transcripts_list):\n",
        "    audio = load_audio(audio_path)\n",
        "    segment = Segment(text=transcript, speaker=speaker_id, audio=audio)\n",
        "    segments.append(segment)\n",
        "  return segments\n",
        "\n",
        "def csm_clone(text,speaker_id,audio_paths):\n",
        "  audio_paths=convert_stereo_to_mono(audio_paths)\n",
        "  segments=get_segments(audio_paths,speaker_id)\n",
        "  audio = generator.generate(\n",
        "    text=text,\n",
        "    speaker=speaker_id,\n",
        "    context=segments,\n",
        "    max_audio_length_ms=10_000,\n",
        "  )\n",
        "  save_path=f\"./result{text[:20]}.wav\"\n",
        "  torchaudio.save(save_path, audio.unsqueeze(0).cpu(), generator.sample_rate)\n",
        "  return save_path\n",
        "\n",
        "\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "def toggle_autoplay(autoplay):\n",
        "    return gr.update(autoplay=autoplay)  # Update instead of creating a new Audio component\n",
        "\n",
        "def ui1():\n",
        "    with gr.Blocks() as demo:\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                text_input = gr.Textbox(label=\"üìù Enter Text\", lines=3)\n",
        "                number_input = gr.Number(label=\"üéôÔ∏è Speaker ID\", value=0)\n",
        "                generate_button = gr.Button(\"üöÄ Generate\")\n",
        "            with gr.Column():\n",
        "                output_audio = gr.Audio(label=\"Generated Audio\", autoplay=True)\n",
        "                with gr.Accordion('‚ñ∂Ô∏è Autoplay', open=False):\n",
        "                    autoplay = gr.Checkbox(value=True, label='Autoplay')\n",
        "                    autoplay.change(toggle_autoplay, inputs=[autoplay], outputs=[output_audio])  # Fixed reference\n",
        "\n",
        "        generate_button.click(csm_tts, inputs=[text_input, number_input], outputs=output_audio)\n",
        "\n",
        "    return demo\n",
        "\n",
        "# tab1 = ui1()\n",
        "# tab1.queue().launch(debug=True, share=True)\n",
        "def tem_csm_clone(text_input, number_input, file_input,multiple_file_input=None):\n",
        "  if multiple_file_input is not None:\n",
        "    clone_path=csm_clone(text_input, number_input,multiple_file_input)\n",
        "  else:\n",
        "    clone_path=csm_clone(text_input, number_input,[file_input])\n",
        "  return clone_path\n",
        "\n",
        "def ui2():\n",
        "    with gr.Blocks() as demo:\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                text_input = gr.Textbox(label=\"üìù Enter Text\", lines=3)\n",
        "                number_input = gr.Number(label=\"üéôÔ∏è Speaker ID\", value=0)\n",
        "                file_input=gr.Audio(label=\"üé§ Record or Upload Reference Audio\",  type='filepath')\n",
        "                generate_button = gr.Button(\"üöÄ Generate\")\n",
        "                with gr.Accordion('üéß Multiple Reference Audio', open=False):\n",
        "                  multiple_file_input = gr.File(label=\"üìÇ Upload Multiple Reference Audios\", type='filepath',file_types=['.wav'], file_count='multiple',value=None)\n",
        "\n",
        "\n",
        "            with gr.Column():\n",
        "                output_audio = gr.Audio(label=\"Generated Audio\", autoplay=True)\n",
        "                with gr.Accordion('‚ñ∂Ô∏è Autoplay', open=False):\n",
        "                    autoplay = gr.Checkbox(value=True, label=\"Autoplay\")\n",
        "                    autoplay.change(toggle_autoplay, inputs=[autoplay], outputs=[output_audio])  # Update autoplay setting\n",
        "\n",
        "        generate_button.click(tem_csm_clone, inputs=[text_input, number_input, file_input,multiple_file_input], outputs=output_audio)\n",
        "\n",
        "    return demo\n",
        "\n",
        "# tab2 = ui2()\n",
        "# tab2.queue().launch(debug=True, share=True)\n",
        "\n",
        "\n",
        "# tab1 = ui1()\n",
        "# tab2 = ui2()\n",
        "# demo = gr.TabbedInterface([tab1, tab2],[\"CSM TTS\",\"CSM VOICE CLONE\"],title=\"CSM-1B\")#,theme='JohnSmith9982/small_and_pretty')\n",
        "# demo.queue().launch(debug=True, share=True)\n",
        "\n",
        "\n",
        "import click\n",
        "@click.command()\n",
        "@click.option(\"--debug\", is_flag=True, default=False, help=\"Enable debug mode.\")\n",
        "@click.option(\"--share\", is_flag=True, default=False, help=\"Enable sharing of the interface.\")\n",
        "def main(debug, share):\n",
        "  tab1 = ui1()\n",
        "  tab2 = ui2()\n",
        "  demo = gr.TabbedInterface([tab1, tab2],[\"CSM TTS\",\"CSM VOICE CLONE\"],title=\"CSM-1B\")#,theme='JohnSmith9982/small_and_pretty')\n",
        "  demo.queue().launch(debug=debug, share=share)\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "lfn_xGlvSSbp",
        "outputId": "169305cc-01d8-4775-e833-152167af670a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/csm/app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/csm\n",
        "!python app.py --share"
      ],
      "metadata": {
        "id": "-EDwLCFnTXtJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}